{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2\n",
    "\n",
    "## Formalia:\n",
    "\n",
    "Please read the [assignment overview page](https://github.com/suneman/socialdata2022/wiki/Assignment-1-and-2) carefully before proceeding. This page contains information about formatting (including formats etc.), group sizes, and many other aspects of handing in the assignment. \n",
    "\n",
    "_If you fail to follow these simple instructions, it will negatively impact your grade!_\n",
    "\n",
    "**Due date and time**: The assignment is due on Monday, March the 28th, 2022 at 23:59. Hand in your files via [http://peergrade.io](http://peergrade.io/).\n",
    "\n",
    "**Peergrading date and time**: _Remember that after handing in you have 1 week to evaluate a few assignments written by other members of the class_. Thus, the peer evaluations are due on Monday, April the 4th, 2022 at 23:59.\n",
    "\n",
    "**Contributions**: In class I told you we will use DTU Learn. But Sune came up with a nicer idea!! **I'll send you a secret id by email later today** so you can add the contributions directly at the end of the notebook. They should look somewhat like this:\n",
    "\n",
    "* id1: did this, this, and this\n",
    "* id2: did that, that, and that\n",
    "* id3: ...\n",
    "\n",
    "**N.B.** It is NOT OK to say that each member contributed equally!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Assignment is based on the last three weeks of the course (Week 6-8). Before going on please load the data with the following line. In this way, you won't need to submit anything else than the .ipynb file and we will be able to run your notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_list = [\"age\", \"sex\", \"race\", \"juv_fel_count\", \"juv_misd_count\", \"juv_other_count\",\n",
    "               \"priors_count\", \"two_year_recid\", \"days_b_screening_arrest\"]\n",
    "\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/suneman/socialdata2022/main/files/recidivism_dataset_sub.csv\", usecols=column_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Predicting criminal recidivism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following exercises are a subset of the ones we did during Week 6. If you have doubts or need more help, go back to the Week 6 notebook. There, you will find additional hints to complete the assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *Exercise 1:* Build a Decision Tree or a Random Forest. \n",
    ">   * Preprocess the data by only keeping records that have between $-30$ and $30$ days between the arrest and screening, then drop the `days_b_screening_arrest` column for the upcoming analysis.\n",
    ">   * Some features we are working with are categorical, so we need to deal with them by using encoders. There are many different types, but we will focus on the `OneHotEncoder` and the `LabelEncoder`:\n",
    ">      * Which encoder did you choose? Describe what it does and why you chose it.\n",
    ">   * Split the data in Train/Test sets by using a 70/30 split and `random_state=42`.\n",
    ">   * Fit a model to your Train set. Choose between a `DecisionTreeClassifier` or a `RandomForestClassifier`. \n",
    ">      * Describe how the model you chose works and why you chose it.\n",
    ">   * Evaluate the performance of model on the test set, i.e compute Accuracy, Precision, and Recall. \n",
    ">      * What are your thoughts on these metrics? Is accuracy a good measure?\n",
    ">   * Are your results tied to the specific hyperparameter set you used? Perform a `RandomizedSearchCV` and recompute the performance metric above with the hyperparameters found. What do you observe?\n",
    ">   * Visualize the tree. There are different options to do so. You can have a look at Week 6 for hints on how to do it. What do you observe?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before going on. Assign the predictions on the test set of your best model to the `y_hat` variable, and their related probabilities to the `y_prob` variable. Remember to use: `y_prob = model.predict_proba(X_test)`\n",
    "\n",
    "**N.B.** Set a specific `random_state` in your model too. Otherwise if we rerun your results we might not be able to reproduce them!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Fairness and bias in Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already know the model you've built is biased. In the next exercises we are going to apply a debiasing method. Please, refer to Week 7, Part 3 for more hints on how to solve these exercises. But first a couple of questions about bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">*Exercise 2.1:* A few questions about bias.\n",
    "> * What are the most common types of data bias? \n",
    "> * What are the potential bias sources/types in our case-study (i.e. recidivism)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *Exercise 2.2:* Equal Odds. We are going to use `y_prob` to debias the ML model for African-Americans and Caucasians.\n",
    ">\n",
    ">    * Define the thresholds as `ths = np.linspace(1e-5,1-1e-5, 10)` and create a function that given a threshold `th` and `y_prob` returns `y_hat` as:\n",
    ">\n",
    ">$$\\begin{cases}\\hat{y}=1, \\mbox{ if } y_{prob} > th \\\\ \\hat{y}=0, \\mbox{ otherwhise}\\end{cases}    \\mbox(1)$$ \n",
    ">\n",
    ">\n",
    ">   * To find the two thresholds that correct for the bias for African-Americans and Caucasians, you can either compute the distance of the ROC curve points or visually find the thresholds (as described in Week 7 Ex. 3.3).\n",
    ">      * Describe the method you have used to find the thresholds (i.e. Visual or Computational) and how you used it to identify the thresholds. What thresholds did you find? \n",
    ">   * Debias the model output by re-computing $\\hat{y}$ with the thresholds you found. \n",
    ">      * **Hint 1** This means that you have to take `y_prob` of your model African-Americans and apply Eq. (1) with the threshold for African-Americans, and then repeat with the different threshold for Caucasians.\n",
    ">      * **Hint 2** You shouldn't rerun your model!\n",
    ">   * Now plot the confusion matrices for African-Americans and Caucasian after you debiased the method. What do you observe? What do you think the problem with this debiasing method is (Refer to Week 7 for more hints)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Communicate your story and results to others"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *Exercise 3* Fill the article below with the title, subtitles, sections, visualizations and references!\n",
    "> \n",
    ">    * **Note 1** Please, have a look at Week 8 for instructions on how to complete the article and make the visualizations.\n",
    ">    * **Note 2** Make sure **you add the code** that generate your visualizations! This is really important.\n",
    ">    * **Note 3** You should have all the necessary inputs to make the visualizations from the exercises in Part 1 and Part 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADD YOUR TITLE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Introduction.** Write your introduction here. Think about the audience. This is an article for the general public, so you should try to make it engaging, relatable, not too technical etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First viz here: (Week 8 Visualization 1) Interactive visualization with Bokeh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results from exploratory data analysis.** Write this section here. The aim is to show that the data is biased, which might have an impact on the model. Relate this part to the first visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Second viz here: (Week 8 Visualization 2) plot with 3 subplots (Feature importances, Confusion Matrix, Percentage difference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results from the classification task.** Write this section here. The aim is to show that the model is biased as it is learning from biased data. Relate this part to the second visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Third viz here: (Week 8 Visualization 3) plot with 2 subplots (ROC curve and selected threshold, TPR and FPR before and after debiasing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results from debiasing method.** Write this section here. The aim is to show that there are methods that can help to enhance fairness in cases as this one. Relate this part to the third visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Limitations and conclusions.** Write this part here. These are your main take aways, the end of your story, where you should also highlight possible implications/limitations of what you presented."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**References.** Any article need good sources! Whenever you make a statement, refer to data sources, previous studies, methods, etc. add a reference. \n",
    "\n",
    "1. reference 1\n",
    "2. reference 2\n",
    "3. reference 3\n",
    "4. etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Assignment Contributions**:\n",
    "\n",
    "* id1\n",
    "* id2\n",
    "* id3"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
